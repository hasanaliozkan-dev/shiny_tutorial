testdata[,"Residuals"] <- scale(testdata[ ,"Observed"]-testdata[ ,"Predicted"])
ll <- pT-pb+1
# CUSUM CHARTS
testdata[,"Cp"]=NULL
testdata[1,"Cp"]=0
#for(i in 2:ll){testdata[i,"Cp"]=max(0,testdata[i,"Residuals"]-kk)}
for(i in 2:ll){testdata[i,"Cp"]=max(0,testdata[i,"Residuals"]-kk+testdata[i-1,"Cp"])}
for(i in (win+1):ll){
mn=(i-win):i
if(testdata[i,"Cp"]>H){mod=lm(testdata[mn,"Cp"]~mn)
if(mod$coef[2]<0){testdata[i,"Cp"]=0}}}
testdata[,"signal"]<- ifelse( testdata[,"Cp"]>H, 1,
ifelse( testdata[,"Cp"]<=H, 0,
NA))
testdata[,"Cp2"]<- ifelse( testdata[,"Cp"]>H, 200,
ifelse( testdata[,"Cp"]<=H, NA,
NA))
tmp <- testdata[,c("Observed", "Predicted","Year","CumDay","Day","s","Residuals","Cp","Cp2","signal")]
cusum_noreset_moderate <- rbind(cusum_noreset_moderate,tmp)
test_startdate <- test_startdate %m+% years(1)
rm(testdata)
rm(tmp)
#rm(dataNum)
}
#  ALGORITHM ENDS HERE
gls_predict <-  c()
write.csv(cusum_noreset_moderate, file="cusum_noreset_moderate")
#############
# CUSUM NO-RESET-ROUTINE
#############
#cusum parameters:
kk <- 1 # agressive:0.5  ---  moderate:1     ----  routine:1
H <- 1.2 # agressive:0.365 --- moderate:0.695 ----  routine:1.2
win <- 7 #sliding window size
cusum_noreset_routine <- data.frame()
test_startdate <- as.Date("2011-09-01")
test_enddate <- as.Date("2011-09-01") %m+% years(10)-days(1)
testdata <-data_test[which(data_test[,"Date"] >= test_startdate & data_test[,"Date"]<= test_enddate),
-which(names(data_test)==c("Date","Total"))]
#
b <- as.numeric(which(data_train[,"Date"] == train_startdate))
T <- as.numeric(which(data_train[,"Date"] == train_enddate))
#
while (test_startdate < test_enddate) {
# elimizdeki test data sini yillik yillik cekiyoruz, taa ki test_startdate >= test_enddate olana kadar
# test data her sene icin yeniden olusturulacak
# test data list oldugu icin onu dataNum diye bir numeric'e donusturup islemlere devam ettim
testdata <-data_test[which(data_test[,"Date"] >= test_startdate & data_test[,"Date"]< test_startdate %m+%years(1)),
-which(names(data_test)==c("Date","Total"))]
#
gls_predict <-  predict(gls_fit_ts,as.data.frame(testdata))[1:dim(testdata)[1]]
#pb ve pT bu testdata'ya aldigimiz verilerin normal data'da kacinci veriye denk geldigini soyluyor
pb <- as.numeric(which(data_test[,"Date"]==test_startdate))
if (test_enddate >= test_startdate %m+% years(1)-days(1)) {
pT <- as.numeric(which(data_test[,"Date"]==test_startdate %m+% years(1)-days(1)))
} else {
pT <- pb + as.numeric(length( which(data_test[,"Date"]>=test_startdate & data_test[,"Date"]<=test_enddate )))-1
}
# SON SENE TAM YIL ise pT ilk satirdaki gibi, DEGILSE PT ikinci satirdaki gibi
# ornegin ilkinde 242'den 242_365-1'e gidecek (1 eylul, 242.gun yapiyor o yuzden 242)
# Bu alttaki test period vs olan degiskenler, sirf grafik cizerken baslik olarak kullanayim diye
testperiod <- paste(lubridate::year(data_test[which(data_test[,"Date"]==test_startdate),"Date"]),"-",lubridate::year(test_startdate %m+% years(1)-days(1)))
testdata[,"Year"] <- c(rep(testperiod,dim(testdata)[1]))
testdata[,"Day"] <- c(1:dim(testdata)[1])
testdata[,"CumDay"] <- c(pb:pT)
testdata[,"s"] <- c(rep(win,dim(testdata)[1]))
# inverse box-cox to transform predicted gls_predict values
# yani transform edilmis haliyle predict ettik ya, onlari geri orijinal skalaya dondurelim:2500
testdata[ ,"Predicted"] <- (lambda*gls_predict + 1)^(1/lambda)
testdata[ ,"Observed"] <- (lambda*testdata[ ,"TransformedTotal"] + 1)^(1/lambda)
# Find error terms
testdata[,"Residuals"] <- scale(testdata[ ,"Observed"]-testdata[ ,"Predicted"])
ll <- pT-pb+1
# CUSUM CHARTS
testdata[,"Cp"]=NULL
testdata[1,"Cp"]=0
#for(i in 2:ll){testdata[i,"Cp"]=max(0,testdata[i,"Residuals"]-kk)}
for(i in 2:ll){testdata[i,"Cp"]=max(0,testdata[i,"Residuals"]-kk+testdata[i-1,"Cp"])}
for(i in (win+1):ll){
mn=(i-win):i
if(testdata[i,"Cp"]>H){mod=lm(testdata[mn,"Cp"]~mn)
if(mod$coef[2]<0){testdata[i,"Cp"]=0}}}
testdata[,"signal"]<- ifelse( testdata[,"Cp"]>H, 1,
ifelse( testdata[,"Cp"]<=H, 0,
NA))
testdata[,"Cp2"]<- ifelse( testdata[,"Cp"]>H, 200,
ifelse( testdata[,"Cp"]<=H, NA,
NA))
tmp <- testdata[,c("Observed", "Predicted","Year","CumDay","Day","s","Residuals","Cp","Cp2","signal")]
cusum_noreset_routine <- rbind(cusum_noreset_routine,tmp)
test_startdate <- test_startdate %m+% years(1)
rm(testdata)
rm(tmp)
#rm(dataNum)
}
end_time <- Sys.time()
end_time-start_time
data_test <- readRDS("/data_test_cusum.Rds")
require(data.table)
require(dplyr)
require(tidyr)
require(surveillance)
require(lubridate)
require(zoo)
library(forecast)
library(MASS)
library(nlme)
library(lubridate)
library(surveillance)
#  EVALUATE THE PERFORMANCES:
setwd('/Users/ZFED/Dropbox/Outbreak Detector/Turkiye_klinikleri_R')
start_time <- Sys.time()
#load("/Users/ZFED/Dropbox/Outbreak Detector/Turkiye_klinikleri_R/gls_fit_ts.Rdata")
gls_fit_ts <- readRDS('~/Desktop/haziran-biyoistatistik/gls_fit_ts.Rds')
#
lambda <- 1.1414141414141414141
data_train <- readRDS("~/Desktop/haziran-biyoistatistik/data_train_cusum.Rds")
data_test <- readRDS("~/Desktop/haziran-biyoistatistik/data_test_cusum.Rds")
train_startdate <- as.Date("2011-09-01")
train_enddate <- as.Date("2011-09-01") %m+% years(10)-days(1)
#############
gls_predict <-  c()
#cusum parameters:
kk <- 0.5 # agressive:0.5  ---  moderate:1     ----  routine:1
H <- 0.365 # agressive:0.365 --- moderate:0.695 ----  routine:1.2
win <- 7 #sliding window size
cusum_allreset_aggressive <- data.frame()
test_startdate <- as.Date("2011-09-01")
test_enddate <- as.Date("2011-09-01") %m+% years(10)-days(1)
testdata <-data_test[which(data_test[,"Date"] >= test_startdate & data_test[,"Date"]<= test_enddate),
-which ( (names(data_test)==c("Date","Total")) ) ]
b <- as.numeric(which(data_train[,"Date"] == train_startdate))
T <- as.numeric(which(data_train[,"Date"] == train_enddate))
testdata <-data_test[which(data_test[,"Date"] >= test_startdate & data_test[,"Date"]< test_startdate %m+%years(1)),
-which(names(data_test)==c("Date","Total"))]
#
gls_predict <-  predict(gls_fit_ts,as.data.frame(testdata))[1:dim(testdata)[1]]
load("~/Desktop/haziran-biyoistatistik/last_train.RData")
load("~/Desktop/haziran-biyoistatistik/last_test.RData")
require(data.table)
require(dplyr)
require(tidyr)
require(surveillance)
require(lubridate)
require(zoo)
library(forecast)
library(MASS)
library(nlme)
library(lubridate)
library(surveillance)
start_time <- Sys.time()
#load("/Users/ZFED/Dropbox/Outbreak Detector/Turkiye_klinikleri_R/gls_fit_ts.Rdata")
gls_fit_ts <- readRDS('~/Desktop/haziran-biyoistatistik/gls_fit_ts.Rds')
#
lambda <- 1.1414141414141414141
data_train <- readRDS("~/Desktop/haziran-biyoistatistik/data_train_cusum.Rds")
data_test <- readRDS("~/Desktop/haziran-biyoistatistik/data_test_cusum.Rds")
View(data_test)
View(testdata_ML)
train_startdate <- as.Date("2011-09-01")
train_enddate <- as.Date("2011-09-01") %m+% years(10)-days(1)
#############
gls_predict <-  c()
#cusum parameters:
kk <- 0.5 # agressive:0.5  ---  moderate:1     ----  routine:1
H <- 0.365 # agressive:0.365 --- moderate:0.695 ----  routine:1.2
win <- 7 #sliding window size
cusum_allreset_aggressive <- data.frame()
test_startdate <- as.Date("2011-09-01")
test_enddate <- as.Date("2011-09-01") %m+% years(10)-days(1)
testdata <-data_test[which(data_test[,"Date"] >= test_startdate & data_test[,"Date"]<= test_enddate),
-which ( (names(data_test)==c("Date","Total")) ) ]
b <- as.numeric(which(data_train[,"Date"] == train_startdate))
T <- as.numeric(which(data_train[,"Date"] == train_enddate))
#
while (test_startdate < test_enddate) {
# elimizdeki test data sini yillik yillik cekiyoruz, taa ki test_startdate >= test_enddate olana kadar
# test data her sene icin yeniden olusturulacak
# test data list oldugu icin onu dataNum diye bir numeric'e donusturup islemlere devam ettim
testdata <-data_test[which(data_test[,"Date"] >= test_startdate & data_test[,"Date"]< test_startdate %m+%years(1)),
-which(names(data_test)==c("Date","Total"))]
#
gls_predict <- predict(gls_fit_ts, data= as.data.frame(testdata))[1:dim(testdata)[1]]
#pb ve pT bu testdata'ya aldigimiz verilerin normal data'da kacinci veriye denk geldigini soyluyor
pb <- as.numeric(which(data_test[,"Date"]==test_startdate))
if (test_enddate >= test_startdate %m+% years(1)-days(1)) {
pT <- as.numeric(which(data_test[,"Date"]==test_startdate %m+% years(1)-days(1)))
} else {
pT <- pb + as.numeric(length( which(data_test[,"Date"]>=test_startdate & data_test[,"Date"]<=test_enddate )))-1
}
# SON SENE TAM YIL ise pT ilk satirdaki gibi, DEGILSE PT ikinci satirdaki gibi
# ornegin ilkinde 242'den 242_365-1'e gidecek (1 eylul, 242.gun yapiyor o yuzden 242)
# Bu alttaki test period vs olan degiskenler, sirf grafik cizerken baslik olarak kullanayim diye
testperiod <- paste(lubridate::year(data_test[which(data_test[,"Date"]==test_startdate),"Date"]),"-",lubridate::year(test_startdate %m+% years(1)-days(1)))
testdata[,"Year"] <- c(rep(testperiod,dim(testdata)[1]))
testdata[,"Day"] <- c(1:dim(testdata)[1])
testdata[,"CumDay"] <- c(pb:pT)
testdata[,"s"] <- c(rep(win,dim(testdata)[1]))
# inverse box-cox to transform predicted gls_predict values
# yani transform edilmis haliyle predict ettik ya, onlari geri orijinal skalaya dondurelim:2500
testdata[ ,"Predicted"] <- (lambda*gls_predict + 1)^(1/lambda)
testdata[ ,"Observed"] <- (lambda*testdata[ ,"TransformedTotal"] + 1)^(1/lambda)
# Find error terms
testdata[,"Residuals"] <- scale(testdata[ ,"Observed"]-testdata[ ,"Predicted"])
ll <- pT-pb+1
# CUSUM CHARTS
testdata[,"Cp"]=NULL
testdata[1,"Cp"]=0
for(i in 2:ll){testdata[i,"Cp"]=max(0,testdata[i,"Residuals"]-kk)}
for(i in (win+1):ll){
mn=(i-win):i
print(testdata[i,"Cp"])
print(i)
if(testdata[i,"Cp"]>H){mod=lm(testdata[mn,"Cp"]~mn)
if(mod$coef[2]<0){testdata[i,"Cp"]=0}}}
testdata[,"signal"]<- ifelse( testdata[,"Cp"]>H, 1,
ifelse( testdata[,"Cp"]<=H, 0,
NA))
testdata[,"Cp2"]<- ifelse( testdata[,"Cp"]>H, 200,
ifelse( testdata[,"Cp"]<=H, NA,
NA))
tmp <- testdata[,c("Observed", "Predicted","Year","CumDay","Day","s","Residuals","Cp","Cp2","signal")]
cusum_allreset_aggressive <- rbind(cusum_allreset_aggressive,tmp)
test_startdate <- test_startdate %m+% years(1)
rm(testdata)
rm(tmp)
#rm(dataNum)
}
View(testdata)
View(testdata)
run
r
?predict
GradesA <- c(25,41,41,54,29,50,54,46,54,33,33,54,37,12,29,41)
GradesB <- c(41,66,92,71,71,54,88,54,70,50,58,79,88,46,67,46,56)
shapiro.test(GradesA)
shapiro.test(GradesB)
var.test(GradesA,GradesB)
t.test(GradesA,GradesB,alternative = "two.sided",mu=0,paired = FALSE,var.equal = TRUE)
library(svDialogs)
db <- as.integer(dlgInput("NUMBER OF DIMENSION ", Sys.info()[""])$res)
#db <- as.integer(readline(prompt="NUMBER OF DIMENSION "))
n <- as.integer(dlgInput("NUMBER OF SUBJECTS ", Sys.info()[""])$res)
#n <- as.integer(readline(prompt="NUMBER OF SUBJECTS"))
k <- as.integer(dlgInput("NUMBER OF LANDMARKS ", Sys.info()[""])$res)
library(svDialogs)
db <- as.integer(dlgInput("NUMBER OF DIMENSION ", Sys.info()[""])$res)
db <- as.integer(dlgInput("NUMBER OF DIMENSION ", Sys.info()[""])$res)
db <- as.integer(dlgInput("NUMBER OF DIMENSION ", Sys.info()[""])$res)
#db <- as.integer(readline(prompt="NUMBER OF DIMENSION "))
n <- as.integer(dlgInput("NUMBER OF SUBJECTS ", Sys.info()[""])$res)
#n <- as.integer(readline(prompt="NUMBER OF SUBJECTS"))
k <- as.integer(dlgInput("NUMBER OF LANDMARKS ", Sys.info()[""])$res)
a=0; rr=0; ka=0; kb=0; sn1=1; tlsr=0; tlr2=0; tr2=0; tr1a=0; tr1b=0;x=0
tl2=0; ts2=0; tlsb2=0; td=0; tlre=0; tsre=0; sn2=0; d=0; trs2=0; srkt=0;i=0;
C = choose(k,2); sn2=(n*(C)); s=C*n;
R<-matrix(nrow=2*n*C,ncol=4)
P<-matrix(nrow=n*C,ncol=4)
V<-matrix(nrow=n*C,ncol=4)
print(C)
for (a in 1:2){
for (b in 1:n){
for (c in 1:C){
d=d+1; R[d,1]=a; R[d,2]=b; R[d,3]=c;
}
}
}
# A ve B matrixlerinin oluşturulması (hazır matrix geldiğinde kaldırmak lazım)
A<-matrix(nrow=n*k,ncol=3)
B<-matrix(nrow=n*k,ncol=3)
for (xyz in 1:n){
for (wrwr in 1:k){
x=x+1;A[x,1]=xyz; A[x,2]=wrwr; A[x,3]=c; B[x,1]=c; B[x,2]=wrwr; B[x,3]=xyz;
}
}
# Reading the matrixes A and B for rater 1 and Rater 2
for (i in 1:(n*k)){
for (j in 1:db){
A[i,j];
B[i,j];
}
}
# Calculation of the Euclidean distances between landmark pairs for raters
if (db < 3){
# calculations for two dimensions
for(p in seq(from = 1, to = n*k, by = k)){
t=k+p; m=t-k;
for (j in m:(t-1)){
for (i in m:(t-1)){
if ((j<i) & (i!=j)){
acia1= sqrt(((A[j,1]-A[i,1])^2)+((A[j,2]-A[i,2])^2));
R[sn1,4]= acia1; sn2=sn2+1;
acib1=sqrt(((B[j,1]-B[i,1])^2)+((B[j,2]-B[i,2])^2));
R[sn2,4]= acib1;
#calculation of sum of squares for lxrxs
tlsr= tlsr + (acia1^2) + (acib1^2);
#calculation of sum of squares for r (cont. Outside the loop)
tr1a= tr1a + acia1; tr1b = tr1b + acib1;
#calculation of adjustment factor (cont. Outside the loop)
td= td + acia1 + acib1;
sn1= sn1+1;
}
}
}
}
}
if (db>2){
#calculations for three dimensions
for(p in seq(from = 1, to = n*k, by = k)){
t=k+p; m=t-k;
for (j in m:(t-1)){
for (i in m:(t-1)){
if ((j<i) & (i!=j)){
acia1=sqrt(((A[j,1] - A[i,1])^2) + ((A[j,2] - A[i,2])^2) + ((A[j,3] - A[i,3])^2));
R[sn1,4]=as.integer(acia1); sn2=sn2+1;
acib1 = sqrt(((B[j,1]- B[i,1])^2) + ((B[j,2]-B[i,2])^2)+((B[j,3]-B[i,3])^2));
R[sn2,4] =as.integer(acib1);
#calculation of sum of squares for lxrxs
tlsr= tlsr + (acia1^2) + (acib1^2);
#calculation of sum of squares for r (cont. Outside the loop)
tr1a= tr1a+ acia1; tr1b=tr1b + acib1;
#calculation of adjustment factor (cont. Outside the loop)
td= td + acia1 + acib1;
sn1= sn1+1;
}
}
}
}
}
#calculation of adjustment factor
df=(td^2)/(2*C*n)
#calculation of sum of square of r and mean of square of r
tr2=(tr1a^2)+(tr1b^2); rkt=(tr2/(C*n))-df; rko=((tr2/(C*n))-df)/1; ms_r=rko;
#Division of R matrix into 2 parts for analysis (P for rater 1, V for rater 2)
for (i in 1:s){
for (j in 1:4){
P[i,j]= R[i,j];
}
}
v=0
xyz=s+1
for (i in xyz:(2*s)){
v=v+1;
for (j in 1:4){
V[v,j]=R[i,j];
}
}
#calculation of sum of squares for l
for (l in 1:C){
tl1=0;
for (i in 1:s){
if (l>P[i,3]-1 & (l <P[i,3]+1)){
tl1=tl1+P[i,4];}
if (l>(V[i,3]-1) & (l<V[i,3]+1)){
tl1=tl1+V[i,4];}
}
tl2=tl2+(tl1^2);
}
lkt=(tl2/(n*2))-df
#calculation of sum of squares for s
for (sb in 1:n){
ts1=0;
for (i in 1:s){
if ((sb>(P[i,2]-1) & sb<(P[i,2]+1))){
ts1=ts1+P[i,4];}
if ((sb>(V[i,2]-1) & sb<(V[i,2]+1))){
ts1=ts1+V[i,4];}
}
ts2=ts2+(ts1^2);
}
skt=(ts2/(C*2))-df;
#calculation of sum of squares for lxs
for (l in 1:C){
for (sb in 1:n){
tls1=0;
for (i in 1:s){
if ((l>(P[i,3]-1)) & (l<(P[i,3]+1))){
if ((sb>(P[i,2]-1)) & (sb<(P[i,2]+1))){
tls1=tls1+P[i,4];}
}
if ((l>(V[i,3]-1) & l<(V[i,3]+1))){
if ((sb>(V[i,2]-1) & sb<(V[i,2]+1))){
tls1=tls1+V[i,4];}
}
}
tlsb2=tlsb2+(tls1^2);
}
}
lskt=(tlsb2/2)-df-lkt-skt;
# calculation of sum of squares for lxr
for (l in 1:C){
tlrp=0;
tlrv=0;
for (i in 1:s){
if ((l>(P[i,3]-1) & l<(P[i,3]+1))){
tlrp=tlrp+P[i,4]; tlrv=tlrv+V[i,4];}
}
tlre=tlre+(tlrp^2+tlrv^2);
}
lrkt=(tlre/n)-df-lkt-rkt;
# calculation of sum of squares for rxs
for (r in 1:2){
for (sb in 1:n){
trsp=0; trsv=0;
for (i in 1:s){
if ((r>(P[i,1]-1) & r<(P[i,1]+1))){
if ((sb>(P[i,2]-1) & sb<(P[i,2]+1))){
trsp=trsp+P[i,4];}
}
if ((r>(V[i,1]-1) & r<(V[i,1]+1))){
if ((sb>(V[i,2]-1) & sb<(V[i,2]+1))){
trsv=trsv+V[i,4];}
}
}
trs2=trs2+(trsp^2)+(trsv^2);
}
}
srkt=(trs2/C)-df-rkt-skt;
#calculation of sum of squares for lxrxs
tlsrkt=tlsr-df-lkt-rkt-skt-lrkt-lskt-srkt
#calculation of Mean Squares
ms_lrs=tlsrkt/((n-1)*(C-1));
ms_lr=lrkt/(C-1);
ms_ls=lskt/((n-1)*(C-1));
ms_rs=srkt/(n-1);
ms_l=lkt/(C-1);
ms_s=skt/(n-1);
#estimates of the variance components
var_lrs=ms_lrs;
var_lr=(ms_lr-ms_lrs)/n;
var_ls=(ms_ls-ms_lrs)/2;
var_rs=(ms_rs-ms_lrs)/C;
var_l=(ms_l-ms_lr-ms_ls+ms_lrs)/(2*n);
var_r=(ms_r-ms_lr-ms_rs+ms_lrs)/(C*n);
var_s=(ms_s-ms_ls-ms_rs+ms_lrs)/(2*C);
if (var_lrs<0){
var_lrs=0;}
if (var_lr<0){
var_lr=0;}
if (var_ls<0){
var_ls=0;}
if (var_rs<0){
var_rs=0;}
if (var_l<0){
var_l=0;}
if (var_r<0){
var_r=0;}
if (var_s<0){
var_s=0;}
var_rel=(var_lr/2)+(var_ls/n)+(var_lrs/(2*n));
G=var_l/(var_l+var_rel);
print('Rater-->r, Subject-->s, Landmark eslestirmesi-->l')
print(' r s l Euclidean distances'); R
print('r sum of square'); rkt
print('l sum of square'); lkt
print('s sum of square'); skt
print('lxs sum of square'); lskt
print('lxr sum of square'); lrkt
print('rxs sum of square'); srkt
print('lxsxr sum of square'); tlsrkt
print('r mean square'); ms_r
print('l mean square'); ms_l
print('s mean square'); ms_s
print('lxs mean square'); ms_ls
print('lxr mean square'); ms_lr
print('rxs mean square'); ms_rs
print('lxrxs mean square'); ms_lrs
print('variance of r'); var_r
print('variance of l'); var_l
print('variance of s'); var_s
print('variance of lxs');var_ls
print('variance of lxr'); var_lr
print('variance of rxs'); var_rs
print('variance of lxrxs'); var_lrs
print('variance of rel'); var_rel
print(G);print('G COEFFICIENT')
for (q in 1:35){
print(q)
q=q+7
}
setwd("~/Desktop/ShinyTutorial")
install.packages('shinythemes')
library(shiny)
library(shiny)
library(shinythemes)
ui <- fluidPage(theme = shinytheme("cerulean"),
navbarPage(
"My First App",
tabPanel("Navbar 1",
sidebarPanel(
tags$h3("Input:"),
textInput("txt1","Given Name: ",""),
textInput("txt2","Surname: ",""),
),
mainPanel(
h1("Header 1"),
h4("Output 1"),
verbatimTextOutput("txtout")
)
),
tabPanel("Navbar 2","Hasan Ali ÖZKAN2"),
tabPanel("Navbar 3","Hasan Ali ÖZKAN3")
),)
server <- function(input, output){
output$txtout <- renderText({
paste(input$txt1,input$txt2,sep = " *** ")
})
}
shinyApp(ui, server)
source('~/Desktop/ShinyTutorial/Lesson1.R')
runApp('Lesson1.R')
install.packages("languageserver")
